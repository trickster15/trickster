{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Ex 10 Implementation of  Hyperparameter optimization Techniques - Manual Search, Random Search, Grid Search, Halving Grid Search, Randomized Search., Automated Hyperparameter tuning, Bayesian Optimization.**"
      ],
      "metadata": {
        "id": "JPRi4IEIGQu0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Import Required Libraries\n",
        "\n",
        "Loads libraries for:\n",
        "\n",
        "Data handling (numpy, pandas)\n",
        "\n",
        "Modeling (RandomForestClassifier)\n",
        "\n",
        "Hyperparameter tuning (GridSearchCV, RandomizedSearchCV, HalvingGridSearchCV, BayesSearchCV, TPOTClassifier)\n",
        "\n",
        "Model evaluation (accuracy_score)\n",
        "\n",
        "warnings.filterwarnings('ignore'): hides warning messages (especially from TPOT).\n",
        "\n",
        "enable_halving_search_cv: enables experimental support for HalvingGridSearch."
      ],
      "metadata": {
        "id": "qBN598R7GYQ3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2i3NhWBCGPa3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize tpot\n",
        "!pip install --upgrade tpot\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GnQrTQAGes2",
        "outputId": "47ef9c85-4775-4d56-d9b4-217fd3e6637b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.11/dist-packages (0.10.2)\n",
            "Requirement already satisfied: tpot in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (25.1.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.5.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: update-checker>=0.16 in /usr/local/lib/python3.11/dist-packages (from tpot) (0.18.0)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.11/dist-packages (from tpot) (4.67.1)\n",
            "Requirement already satisfied: stopit>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from tpot) (1.1.2)\n",
            "Requirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from tpot) (2.2.2)\n",
            "Requirement already satisfied: xgboost>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from tpot) (2.1.4)\n",
            "Requirement already satisfied: matplotlib>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from tpot) (3.10.0)\n",
            "Requirement already satisfied: traitlets>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from tpot) (5.14.3)\n",
            "Requirement already satisfied: lightgbm>=3.3.3 in /usr/local/lib/python3.11/dist-packages (from tpot) (4.5.0)\n",
            "Requirement already satisfied: optuna>=3.0.5 in /usr/local/lib/python3.11/dist-packages (from tpot) (4.2.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from tpot) (3.4.2)\n",
            "Requirement already satisfied: dask>=2024.4.2 in /usr/local/lib/python3.11/dist-packages (from tpot) (2024.12.1)\n",
            "Requirement already satisfied: distributed>=2024.4.2 in /usr/local/lib/python3.11/dist-packages (from tpot) (2024.12.1)\n",
            "Requirement already satisfied: dask-expr>=1.0.12 in /usr/local/lib/python3.11/dist-packages (from tpot) (1.1.21)\n",
            "Requirement already satisfied: dask-jobqueue>=0.8.5 in /usr/local/lib/python3.11/dist-packages (from tpot) (0.9.0)\n",
            "Requirement already satisfied: func-timeout>=4.3.5 in /usr/local/lib/python3.11/dist-packages (from tpot) (4.3.5)\n",
            "Requirement already satisfied: configspace>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from tpot) (1.2.1)\n",
            "Requirement already satisfied: dill>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from tpot) (0.3.9)\n",
            "Requirement already satisfied: seaborn>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from tpot) (0.13.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from configspace>=1.1.1->tpot) (3.2.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from configspace>=1.1.1->tpot) (4.13.0)\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from configspace>=1.1.1->tpot) (10.6.0)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask>=2024.4.2->tpot) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2024.4.2->tpot) (3.1.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2024.4.2->tpot) (2025.3.2)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2024.4.2->tpot) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from dask>=2024.4.2->tpot) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2024.4.2->tpot) (0.12.1)\n",
            "Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2024.4.2->tpot) (8.6.1)\n",
            "Requirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.11/dist-packages (from dask-expr>=1.0.12->tpot) (18.1.0)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.2->tpot) (3.1.6)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.2->tpot) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.2->tpot) (1.1.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.2->tpot) (5.9.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.2->tpot) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.2->tpot) (3.1.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.2->tpot) (6.4.2)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.2->tpot) (2.3.0)\n",
            "Requirement already satisfied: zict>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.2->tpot) (3.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->tpot) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->tpot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->tpot) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->tpot) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->tpot) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->tpot) (2.8.2)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.0.5->tpot) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna>=3.0.5->tpot) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.0.5->tpot) (2.0.40)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->tpot) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->tpot) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from update-checker>=0.16->tpot) (2.32.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost>=1.7.0->tpot) (2.21.5)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.0.5->tpot) (1.1.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask>=2024.4.2->tpot) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.10.3->distributed>=2024.4.2->tpot) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.2->tpot) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.0.5->tpot) (3.1.1)\n",
            "Requirement already satisfied: tpot in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from tpot) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from tpot) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn<1.6,>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from tpot) (1.5.2)\n",
            "Requirement already satisfied: update-checker>=0.16 in /usr/local/lib/python3.11/dist-packages (from tpot) (0.18.0)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.11/dist-packages (from tpot) (4.67.1)\n",
            "Requirement already satisfied: stopit>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from tpot) (1.1.2)\n",
            "Requirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from tpot) (2.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from tpot) (1.4.2)\n",
            "Requirement already satisfied: xgboost>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from tpot) (2.1.4)\n",
            "Requirement already satisfied: matplotlib>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from tpot) (3.10.0)\n",
            "Requirement already satisfied: traitlets>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from tpot) (5.14.3)\n",
            "Requirement already satisfied: lightgbm>=3.3.3 in /usr/local/lib/python3.11/dist-packages (from tpot) (4.5.0)\n",
            "Requirement already satisfied: optuna>=3.0.5 in /usr/local/lib/python3.11/dist-packages (from tpot) (4.2.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from tpot) (3.4.2)\n",
            "Requirement already satisfied: dask>=2024.4.2 in /usr/local/lib/python3.11/dist-packages (from tpot) (2024.12.1)\n",
            "Requirement already satisfied: distributed>=2024.4.2 in /usr/local/lib/python3.11/dist-packages (from tpot) (2024.12.1)\n",
            "Requirement already satisfied: dask-expr>=1.0.12 in /usr/local/lib/python3.11/dist-packages (from tpot) (1.1.21)\n",
            "Requirement already satisfied: dask-jobqueue>=0.8.5 in /usr/local/lib/python3.11/dist-packages (from tpot) (0.9.0)\n",
            "Requirement already satisfied: func-timeout>=4.3.5 in /usr/local/lib/python3.11/dist-packages (from tpot) (4.3.5)\n",
            "Requirement already satisfied: configspace>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from tpot) (1.2.1)\n",
            "Requirement already satisfied: dill>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from tpot) (0.3.9)\n",
            "Requirement already satisfied: seaborn>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from tpot) (0.13.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from configspace>=1.1.1->tpot) (3.2.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from configspace>=1.1.1->tpot) (4.13.0)\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from configspace>=1.1.1->tpot) (10.6.0)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask>=2024.4.2->tpot) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2024.4.2->tpot) (3.1.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2024.4.2->tpot) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2024.4.2->tpot) (24.2)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2024.4.2->tpot) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from dask>=2024.4.2->tpot) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2024.4.2->tpot) (0.12.1)\n",
            "Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2024.4.2->tpot) (8.6.1)\n",
            "Requirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.11/dist-packages (from dask-expr>=1.0.12->tpot) (18.1.0)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.2->tpot) (3.1.6)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.2->tpot) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.2->tpot) (1.1.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.2->tpot) (5.9.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.2->tpot) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.2->tpot) (3.1.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.2->tpot) (6.4.2)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.2->tpot) (2.3.0)\n",
            "Requirement already satisfied: zict>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.2->tpot) (3.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->tpot) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->tpot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->tpot) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->tpot) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->tpot) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->tpot) (2.8.2)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.0.5->tpot) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna>=3.0.5->tpot) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.0.5->tpot) (2.0.40)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->tpot) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->tpot) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.6,>=1.4.2->tpot) (3.6.0)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from update-checker>=0.16->tpot) (2.32.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost>=1.7.0->tpot) (2.21.5)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.0.5->tpot) (1.1.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask>=2024.4.2->tpot) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.10.3->distributed>=2024.4.2->tpot) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.2->tpot) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.0.5->tpot) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Load iris dataset and split the dataset\n",
        "\n",
        "Loads the Iris dataset, a classic multi-class classification dataset (3 flower species).\n",
        "\n",
        "X: Features (sepal/petal length/width)\n",
        "\n",
        "y: Target labels (species)\n",
        "\n",
        "Splits the dataset into:\n",
        "\n",
        "80% training\n",
        "\n",
        "20% testing\n",
        "\n",
        "Create the results dictionary"
      ],
      "metadata": {
        "id": "h_8HKepRGfl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "results= {}\n"
      ],
      "metadata": {
        "id": "-wPRFz4dGikW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Manual Search (Baseline)\n",
        "\n",
        "You manually choose a set of hyperparameters based on intuition or trial and error.\n",
        "\n",
        "Sets fixed values for n_estimators and max_depth manually.\n",
        "\n",
        "Trains and evaluates the model.\n",
        "\n",
        "Used as a baseline for comparison."
      ],
      "metadata": {
        "id": "HaHsXFuxGmrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "acc_manual=accuracy_score(y_test, model.predict(X_test))\n",
        "results['Manual Search'] = acc_manual\n",
        "print(\"Manual Search Accuracy:\", acc_manual)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgejN_S1Gnkj",
        "outputId": "336f504e-2c6b-4bd5-c4d8-b8c35ea6656d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual Search Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Random Search\n",
        "\n",
        "Tries a random subset of hyperparameter combinations from a distribution, not a grid.\n",
        "\n",
        "Imports Python’s built-in random module.\n",
        "\n",
        "This module allows you to randomly select values from a list.\n",
        "n_estimators is a key hyperparameter for a Random Forest model.\n",
        "\n",
        "It defines the number of decision trees in the forest.\n",
        "\n",
        "This line randomly picks one value from the list [50, 100, 150].\n",
        "\n",
        "If random.choice() selects 100, the forest will consist of 100 trees.\n",
        "\n",
        "max_depth controls the maximum depth of each decision tree.\n",
        "\n",
        "A tree's depth is the number of splits it can make from root to leaf.\n",
        "\n",
        "None means the tree is allowed to grow until all leaves are pure or contain fewer samples than min_samples_split.\n",
        "\n",
        "If random.choice() selects 3, trees will only grow to depth 3.\n",
        "\n",
        "If None, the trees can grow very deep (risk of overfitting).\n",
        "\n",
        "Instantiates a RandomForestClassifier using the randomly selected values for:\n",
        "\n",
        "n_estimators\n",
        "\n",
        "max_depth\n",
        "\n",
        "random_state=42 ensures reproducibility (you get the same results every time the code is run with same settings).\n",
        "\n",
        "Trains (fits) the Random Forest model using the training dataset (X_train, y_train).\n",
        "\n",
        "The model learns patterns from the data by constructing multiple decision trees and averaging their outputs (or majority voting for classification).\n",
        "\n",
        "Predicts the class labels for the test dataset (X_test) using the trained model.\n",
        "\n",
        "Each tree votes, and the class with the most votes is the final prediction.\n",
        "\n",
        "Compares the actual labels (y_test) with the predicted labels.\n",
        "\n",
        "Calculates the accuracy: the proportion of correct predictions over total predictions.\n",
        "\n",
        "Prints the accuracy of the model using the randomly selected parameters.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "88zPMfn6GoTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "n_estimators = random.choice([50, 100, 150])\n",
        "max_depth = random.choice([2, 3, 5, None])\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "acc_random= accuracy_score(y_test, model.predict(X_test))\n",
        "results['Random Search'] = acc_random\n",
        "print(\"Random Search Accuracy:\", acc_random)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1C8IlCmGq1_",
        "outputId": "c99b29dd-0651-415a-800c-de1f1a65e1a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Search Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Grid Search (Exhaustive)\n",
        "\n",
        "Tries all combinations of the given hyperparameter values.\n",
        "\n",
        "Cross-validates (3-fold CV) each combination.\n",
        "\n",
        "Returns the best combination based on performance.\n",
        "\n",
        "Time-consuming for large parameter sets but very thorough.\n",
        "\n",
        "This is a dictionary of hyperparameters we want to explore for the model.\n",
        "\n",
        "Each key is a hyperparameter of RandomForestClassifier.\n",
        "\n",
        "Each value is a list of possible values to test.\n",
        "\n",
        "GridSearchCV is a scikit-learn class for exhaustive search over hyperparameter combinations.\n",
        "\n",
        "RandomForestClassifier(random_state=42) → The model we want to tune.\n",
        "\n",
        "param_grid → The dictionary of hyperparameters to try.\n",
        "\n",
        "cv=3 → Use 3-fold cross-validation:\n",
        "\n",
        "The training data (X_train, y_train) is split into 3 parts.\n",
        "\n",
        "Each model is trained on 2 parts and validated on the 3rd.\n",
        "\n",
        "This is repeated 3 times (rotating the validation part).\n",
        "\n",
        "The scores are averaged to reduce variance and avoid overfitting.\n",
        "\n",
        "Trains the model using all 8 hyperparameter combinations.\n",
        "\n",
        "For each combination:\n",
        "\n",
        "Runs 3-fold CV on X_train\n",
        "\n",
        "Measures performance (e.g., accuracy by default)\n",
        "\n",
        "Chooses the best combination based on CV score.\n",
        "\n",
        ".best_params_ gives you the hyperparameter values that performed best during CV.\n",
        "\n",
        "Example Output:\n",
        "Grid Search Best Params: {'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 100}\n",
        "\n",
        "Makes predictions on the test set using the best model found and Calculates accuracy.\n"
      ],
      "metadata": {
        "id": "yjp8jstuGr1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [3, None],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"Grid Search Best Params:\", grid_search.best_params_)\n",
        "acc_gridsearch= accuracy_score(y_test, grid_search.predict(X_test))\n",
        "results['Grid Search'] = acc_gridsearch\n",
        "print(\"Grid Search Accuracy:\", acc_gridsearch)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqwEk34RGvao",
        "outputId": "ac3dbc7d-9061-461e-f132-e4407f2a8258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid Search Best Params: {'criterion': 'gini', 'max_depth': None, 'n_estimators': 50}\n",
            "Grid Search Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Halving Grid Search\n",
        "\n",
        "HalvingGridSearchCV is a smarter and more efficient version of GridSearchCV. Instead of testing all combinations of parameters exhaustively, it:\n",
        "\n",
        "Starts with many candidates trained on fewer resources (e.g., samples).\n",
        "\n",
        "In each iteration, it eliminates the worst-performing combinations and allocates more resources to the better ones.\n",
        "\n",
        "This \"successive halving\" makes it much faster and scalable, especially with large datasets or expensive models.\n",
        "\n",
        "param_grid → A dictionary of hyperparameter combinations to search through:\n",
        "\n",
        "cv=3 → Uses 3-fold cross-validation:\n",
        "\n",
        "Splits the training data into 3 parts.\n",
        "\n",
        "Trains on 2 parts, validates on the remaining one, and rotates.\n",
        "\n",
        "Starts training the model using the successive halving algorithm:\n",
        "\n",
        "Initially trains all combinations on a small subset of data.\n",
        "\n",
        "Selects the best-performing half.\n",
        "\n",
        "In the next round, only trains those selected models on more data.\n",
        "\n",
        "Repeats until the best model is found.\n",
        "\n",
        "It’s significantly more resource-efficient than traditional grid search, especially for large parameter grids or datasets.\n",
        "\n",
        "After halving and validation, it gives you the best combination of hyperparameters that performed well across all rounds.\n",
        "\n",
        "Predicts the labels for the test dataset using the best model found.\n",
        "\n",
        "Calculates accuracy by comparing predicted labels with actual y_test."
      ],
      "metadata": {
        "id": "VHJ53B3AGxcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "halving_search = HalvingGridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3)\n",
        "halving_search.fit(X_train, y_train)\n",
        "print(\"Halving Grid Best Params:\", halving_search.best_params_)\n",
        "acc_halvinggrid = accuracy_score(y_test, halving_search.predict(X_test))\n",
        "results['Halving Grid Search'] = acc_halvinggrid\n",
        "print(\"Halving Grid Search Accuracy:\", acc_halvinggrid)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wRYhhNNG1zK",
        "outputId": "7ac3549b-5ec9-474c-e638-34c804ddd713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Halving Grid Best Params: {'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 100}\n",
            "Halving Grid Search Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "g9AyjZjlMQkD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Randomized Search\n",
        "\n",
        "\n",
        "RandomizedSearchCV is a technique for hyperparameter optimization. Instead of trying every possible combination like in GridSearchCV, it:\n",
        "\n",
        "Randomly samples a fixed number of parameter combinations.\n",
        "\n",
        "This makes it faster and more efficient—especially when the parameter space is large.\n",
        "\n",
        "Imports the randint function from scipy.stats, which is used to specify a range of integer values for random sampling.\n",
        "\n",
        "Unlike lists in GridSearchCV, here we define distributions from which values will be randomly picked.\n",
        "\n",
        "aram_dist is a dictionary of parameter distributions.\n",
        "\n",
        "Instead of providing fixed values, we're giving ranges:\n",
        "\n",
        "n_estimators\tIntegers from 10 to 199\n",
        "max_depth\tIntegers from 1 to 9\n",
        "Each combination in the search will randomly pick a value from each of these ranges.\n",
        "\n",
        "RandomForestClassifier(random_state=42): The model you want to tune.\n",
        "\n",
        "param_distributions=param_dist: The distributions you want to sample from.\n",
        "\n",
        "n_iter=10: Run the model for 10 different random combinations.\n",
        "\n",
        "cv=3: Perform 3-fold cross-validation for each random combination.\n",
        "\n",
        "The search begins:\n",
        "\n",
        "Randomly selects 10 different combinations from the param_dist.\n",
        "\n",
        "For each one, performs 3-fold cross-validation.\n",
        "\n",
        "Computes the average performance metric (accuracy by default).\n",
        "\n",
        "Finds and stores the best performing model and parameters.\n",
        "\n",
        "Displays the best parameter combination found from the 10 random tries.\n",
        "\n",
        "Uses the best model found to:\n",
        "\n",
        "Predict labels on the unseen test set.\n",
        "\n",
        "Calculate the accuracy by comparing predictions to y_test."
      ],
      "metadata": {
        "id": "whJOFqKFG20t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import randint\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': randint(10, 200),\n",
        "    'max_depth': randint(1, 10)\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(RandomForestClassifier(random_state=42), param_distributions=param_dist, n_iter=10, cv=3)\n",
        "random_search.fit(X_train, y_train)\n",
        "print(\"Randomized Search Best Params:\", random_search.best_params_)\n",
        "acc_randomizedsearch = accuracy_score(y_test, random_search.predict(X_test))\n",
        "results['Randomized Search'] = acc_randomizedsearch\n",
        "print(\"Randomized Search Accuracy:\", acc_randomizedsearch)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F90MX0i0G5QF",
        "outputId": "1b5f60b8-5f1a-430d-bbfd-92fec85f040a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Randomized Search Best Params: {'max_depth': 6, 'n_estimators': 104}\n",
            "Randomized Search Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Bayesian Optimization (with BayesSearchCV)\n",
        "\n",
        "Bayesian Optimization builds a probabilistic model of the objective function and uses it to select the most promising hyperparameters to evaluate next, aiming to minimize the number of iterations while still finding the best results.\n",
        "\n",
        "It balances:\n",
        "\n",
        "Exploration (trying new combinations) and\n",
        "\n",
        "Exploitation (focusing on promising areas).\n",
        "\n",
        "Imports BayesSearchCV, the scikit-optimize tool that wraps around scikit-learn estimators to perform Bayesian hyperparameter optimization.\n",
        "\n",
        "You're specifying the range for each hyperparameter to search:\n",
        "\n",
        "'n_estimators': Number of trees in the forest → from 10 to 200\n",
        "\n",
        "'max_depth': Maximum depth of each tree → from 1 to 10\n",
        "\n",
        "These ranges are continuous integer intervals and BayesSearchCV will intelligently sample values from them.\n",
        "\n",
        "RandomForestClassifier(random_state=42)\tThe model to optimize\n",
        "search_spaces=search_space\tThe parameter ranges defined above\n",
        "n_iter=20\tPerform 20 iterations (try 20 different parameter combinations)\n",
        "cv=3\tUse 3-fold cross-validation for each combination\n",
        "During these 20 iterations, the algorithm uses a probabilistic model (like Gaussian Processes) to predict which parameter combination will likely perform best and then evaluates it.\n",
        "\n",
        "The fit() method starts the optimization process:\n",
        "\n",
        "Selects initial hyperparameters (randomly or via prior)\n",
        "\n",
        "Builds a surrogate model (a probability model of the objective function)\n",
        "\n",
        "Selects next points based on expected improvement\n",
        "\n",
        "Updates the model iteratively\n",
        "\n",
        "Displays the best parameter combination discovered during the search.\n",
        "\n",
        "Uses the best model found to:\n",
        "\n",
        "Predict outcomes on the test set\n",
        "\n",
        "Measure and print the accuracy"
      ],
      "metadata": {
        "id": "Xf8UsITbG_Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "\n",
        "search_space = {\n",
        "    'n_estimators': (10, 200),\n",
        "    'max_depth': (1, 10)\n",
        "}\n",
        "\n",
        "opt = BayesSearchCV(RandomForestClassifier(random_state=42), search_spaces=search_space, n_iter=20, cv=3)\n",
        "opt.fit(X_train, y_train)\n",
        "print(\"Bayes Search Best Params:\", opt.best_params_)\n",
        "acc_bayesiansearch = accuracy_score(y_test, opt.predict(X_test))\n",
        "results['Bayesian Optimization'] = acc_bayesiansearch\n",
        "print(\"Bayesian Optimization Accuracy:\", acc_bayesiansearch)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHGA10rrHEjo",
        "outputId": "4987d169-5cc3-4404-fc19-8509237b3e81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bayes Search Best Params: OrderedDict([('max_depth', 5), ('n_estimators', 50)])\n",
            "Bayesian Optimization Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Comparative analysis of optimization techniques"
      ],
      "metadata": {
        "id": "UgvQ55V0HFxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n Accuracy Comparison of Hyperparameter Optimization Techniques:\\n\")\n",
        "df_results = pd.DataFrame(list(results.items()), columns=['Technique', 'Accuracy'])\n",
        "print(df_results.sort_values(by='Accuracy', ascending=False).to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1KdldweHaXr",
        "outputId": "1fc62774-100d-40fb-8541-0bcd7778485a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Accuracy Comparison of Hyperparameter Optimization Techniques:\n",
            "\n",
            "            Technique  Accuracy\n",
            "        Manual Search       1.0\n",
            "        Random Search       1.0\n",
            "          Grid Search       1.0\n",
            "  Halving Grid Search       1.0\n",
            "    Randomized Search       1.0\n",
            "Bayesian Optimization       1.0\n"
          ]
        }
      ]
    }
  ]
}